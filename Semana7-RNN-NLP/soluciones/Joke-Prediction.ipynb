{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Este notebook require Tensorflow 2.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = \"\"\n",
    "\n",
    "joke_url = \"https://raw.githubusercontent.com/Daronspence/One-Liners/master/jokes.txt\"\n",
    "filepath = keras.utils.get_file(\"test.txt\", joke_url)\n",
    "with open(filepath) as f:\n",
    "    joke_text = f.read()\n",
    "\n",
    "jokes += joke_text\n",
    "\n",
    "joke_url = \"http://www.textfiles.com/humor/TAGLINES/taglines.txt\"\n",
    "filepath = keras.utils.get_file(\"test.txt\", joke_url)\n",
    "with open(filepath) as f:\n",
    "    joke_text = f.read()\n",
    "    \n",
    "jokes += joke_text\n",
    "\n",
    "joke_url = \"https://raw.githubusercontent.com/simonaco/25daysofserverless/master/jokes.txt\"\n",
    "filepath = keras.utils.get_file(\"test.txt\", joke_url)\n",
    "with open(filepath) as f:\n",
    "    joke_text = f.read()\n",
    "    \n",
    "jokes += joke_text\n",
    "\n",
    "jokes = jokes.replace(\"\\n\", \" \")\n",
    "jokes = jokes.replace(\"$\", \" \")\n",
    "jokes = jokes.replace('\"', \" \")\n",
    "jokes = jokes.replace('%', \" \")\n",
    "jokes = jokes.replace('&', \" \")\n",
    "jokes = jokes.replace(\"'\", \" \")\n",
    "jokes = jokes.replace(\"-\", \" \")\n",
    "jokes = jokes.replace(\";\", \"\")\n",
    "jokes = jokes.replace(\":\", \"\")\n",
    "jokes = jokes.replace(\"=\", \"\")\n",
    "jokes = jokes.replace(\",\", \"\")\n",
    "    \n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(jokes)\n",
    "max_id = len(tokenizer.word_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#model = keras.models.load_model('shakespeare-stateless.h5')\n",
    "model = keras.models.load_model('jokes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = preprocess([\"what is\"])\n",
    "Y_pred = model.predict_classes(X_new)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # primera oracion ultimo caracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La temperatura es un hiperpar√°metro de los LSTM (y las redes neuronales en general) que se utiliza para controlar la aleatoriedad de las predicciones escalando los logits antes de aplicar softmax.\n",
    "\n",
    "Cuando la temperatura es 1, calculamos el softmax directamente en los logits (la salida sin escala de capas anteriores)\n",
    "\n",
    "https://cs.stackexchange.com/questions/79241/what-is-temperature-in-lstm-and-neural-networks-generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char(\"How are yo\", temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=300, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text(\"my mom\", temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
